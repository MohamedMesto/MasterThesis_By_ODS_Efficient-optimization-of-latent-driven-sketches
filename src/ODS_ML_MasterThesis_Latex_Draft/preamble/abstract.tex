\section*{Abstract}

% gap
Data volumes keep growing, and so efficiently prioritizing information in a gigantic mass becomes indispensable. In use cases like the detection of denial of service (DoS) attacks or identifying the most frequently purchased products in a stream, the importance of an item is typically its count, leading to the detection problem. Yet, the resources available to filter the data to the most relevant are scarce in the face of the gigantic workload. A broader and more holistic representation of the entirety of the data is necessary. When it comes to latent representation, yet, changes on the data become per nature hard to carry over. The most important case of data changing is when the dataset to represent is dynamic: the distribution of the dataset to store—the concept— varies over time—drifts—: there is a concept drift.


% solution
We want to keep only the top most important items at all times. At the same time, guarantees should be provided in our vertical. We represent the same information in a combination of more latent representation on lower-importance items and more explicit representation on higher-importance items by designing a top k pyramid pooling structure. To overcome concept drift, we apply adaptive learning to keep our model dynamic. Moreover, we use neural networks combined with sketches to train the neural network, i.e., instead of feeding the ground-truth counts as labels to the network, we feed the output of sketches that we get
from the whole system.

% results (with numbers)
Our model predicts item counts with a decent accuracy after pyramid pooling is integrated -- error metric dramatically goes down. At the same time, for identifying heavy hitters, the adaptive learning setup outperforms the non-adaptive learning setup and thus effectively address concept drift. With semi-supervised learning (relabeling use output of sketch), we even achieve a new high of AUC score over 0.7 given that our dataset size is strongly limited.

